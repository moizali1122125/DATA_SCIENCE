{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopensearch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopensearch\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenSearch\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopensearch\u001b[39;00m \u001b[39mimport\u001b[39;00m helpers\n",
      "File \u001b[1;32mc:\\Users\\MOIZ\\.conda\\envs\\open\\lib\\site-packages\\opensearch\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdescription\u001b[39;00m \u001b[39mimport\u001b[39;00m Description\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mquery\u001b[39;00m \u001b[39mimport\u001b[39;00m Query, Param\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m Client\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'description'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import opensearch\n",
    "from opensearch import OpenSearch\n",
    "from opensearch import helpers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"secret.env\")\n",
    "\n",
    "class Reader(object):\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "    \n",
    "    def run(self):\n",
    "        df = pd.read_csv(self.file_name, chunksize=3000)\n",
    "        df = next(df)\n",
    "        df = df.fillna(\"\")\n",
    "        return df\n",
    "\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    def get_token(self, documents):\n",
    "        sentences  = [documents]\n",
    "        sentence_embeddings = self.model.encode(sentences)\n",
    "        _ = list(sentence_embeddings.flatten())\n",
    "        encod_np_array = np.array(_)\n",
    "        encod_list = encod_np_array.tolist()\n",
    "        return encod_list\n",
    "\n",
    "class OpenSearchImports(object):\n",
    "    def __init__(self, df, index_name='posting'):\n",
    "        self.df = df\n",
    "        self.index_name = index_name\n",
    "        self.client = OpenSearch(\n",
    "            [os.getenv(\"ENDPOINT\")],\n",
    "            http_auth=(os.getenv(\"USERNAME\"), os.getenv(\"PASSWORD\")),\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            ca_certs=certifi.where())\n",
    "        \n",
    "    def run(self):\n",
    "        elk_data = self.df.to_dict(\"records\")\n",
    "        for job in elk_data:\n",
    "            try:\n",
    "                helper_token = Tokenizer()\n",
    "                embeddings = helper_token.get_token(job[\"jobpost\"])\n",
    "                job[\"vectors\"] = embeddings\n",
    "                self.client.index(index=self.index_name, body=job)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "class OpenSearchQuery(object):\n",
    "    def __init__(self, index_name='posting', endpoint=os.getenv(\"ENDPOINT\")):\n",
    "        self.index_name = index_name\n",
    "        self.endpoint = endpoint\n",
    "        self.client = OpenSearch(\n",
    "            [self.endpoint],\n",
    "            http_auth=(os.getenv(\"USERNAME\"), os.getenv(\"PASSWORD\")),\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            ca_certs=certifi.where())\n",
    "        \n",
    "    def run(self, query):\n",
    "        helper_token = Tokenizer()\n",
    "        embeddings = helper_token.get_token(query)\n",
    "        search_query = {\n",
    "            \"size\": 50,\n",
    "            \"_source\": [\"Title\", \"log_file_path\", \"line_number\"],\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"vectors\": {\n",
    "                        \"vector\": embeddings,\n",
    "                        \"k\": 20}}}}\n",
    "\n",
    "        # Perform the search\n",
    "        res = self.client.search(index=self.index_name, body=search_query, request_timeout=55)\n",
    "        results = []\n",
    "        for hit in res[\"hits\"][\"hits\"]:\n",
    "            result = {\n",
    "                \"title\": hit[\"_source\"][\"Title\"],\n",
    "                \"log_file_path\": hit[\"_source\"][\"log_file_path\"],\n",
    "                \"line_number\": hit[\"_source\"][\"line_number\"]\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Load the log data from the log file\n",
    "with open(\"log_file.txt\", \"r\") as f:\n",
    "    log_data = f.read()\n",
    "\n",
    "# Import the log data into the OpenSearch index with embeddings\n",
    "helper = Reader(file_name=log_data)\n",
    "df = helper.run()\n",
    "helper_elk = OpenSearchImports(df=df)\n",
    "helper_elk.run()\n",
    "\n",
    "# Perform a semantic search on the OpenSearch index\n",
    "INPUT = input(\"Enter the Input Query \")\n",
    "helper_query = OpenSearchQuery()\n",
    "results = helper_query.run(INPUT)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
